{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train_images: 852611\n",
      "Number of validation_images: 54422\n",
      "train and valid generator is ok\n",
      "steps_per_epoch: 26644.09375\n",
      "validation_steps: 1700.6875\n",
      "(?, 2048)\n",
      "Epoch 1/5\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.7930 - acc: 0.7576\n",
      "Epoch 00001: val_acc improved from -inf to 0.70051, saving model to /mogu/lingfei/project/cate4/resnet50/model_file/weight-0.7005071478402407.hdf5\n",
      "26645/26644 [==============================] - 24774s 930ms/step - loss: 0.7930 - acc: 0.7575 - val_loss: 1.0683 - val_acc: 0.7005\n",
      "Epoch 2/5\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.6331 - acc: 0.8063\n",
      "Epoch 00002: val_acc improved from 0.70051 to 0.80958, saving model to /mogu/lingfei/project/cate4/resnet50/model_file/weight-0.8095806842799014.hdf5\n",
      "26645/26644 [==============================] - 24002s 901ms/step - loss: 0.6331 - acc: 0.8063 - val_loss: 0.6315 - val_acc: 0.8096\n",
      "Epoch 3/5\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.8211\n",
      "Epoch 00003: val_acc did not improve\n",
      "26645/26644 [==============================] - 23934s 898ms/step - loss: 0.5854 - acc: 0.8211 - val_loss: 0.7608 - val_acc: 0.7737\n",
      "Epoch 4/5\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.5497 - acc: 0.8318\n",
      "Epoch 00004: val_acc did not improve\n",
      "26645/26644 [==============================] - 28490s 1s/step - loss: 0.5497 - acc: 0.8318 - val_loss: 0.7482 - val_acc: 0.7883\n",
      "Epoch 5/5\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.8395\n",
      "Epoch 00005: val_acc improved from 0.80958 to 0.82871, saving model to /mogu/lingfei/project/cate4/resnet50/model_file/weight-0.8287089779912244.hdf5\n",
      "26645/26644 [==============================] - 24749s 929ms/step - loss: 0.5260 - acc: 0.8395 - val_loss: 0.5586 - val_acc: 0.8287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8b18f1d68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# config\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TRIAN_TXT= '/mogu/lingfei/project/cate4/train_data/cate4_look_merchandise_weibo_train.txt'\n",
    "NUM_CLASSES =24\n",
    "INPUT_HEIGHT,INPUT_WIDTH =224, 224\n",
    "MODEL_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/' + 'resnet50.json'\n",
    "BEST_WEIGHTS_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/'+'weight-{val_acc}.hdf5'\n",
    "TF_LOG_DIR = '/mogu/lingfei/project/cate4/resnet50/log'\n",
    "\n",
    "#the epoch of diff steps\n",
    "EPOCHS1 = 2\n",
    "EPOCHS2 = 4\n",
    "EPOCHS3 = 5\n",
    "\n",
    "#use diff learning rate in diff steps\n",
    "LR1 = 0.001\n",
    "LR2 = 0.0005\n",
    "LR3 = 0.0001\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# prepare data and data augmentation\n",
    "# ------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def load_img_array(image_name, grayscale=False, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n",
    "    img = image.load_img(image_name, grayscale)\n",
    "    resize_img = img.resize(target_size)\n",
    "    img_array = image.img_to_array(resize_img)/ 255.0\n",
    "    return img_array\n",
    "\n",
    "def random_hue_saturation_value(image,\n",
    "                                hue_shift_limit=(-15, 15),\n",
    "                                sat_shift_limit=(-0.025, 0.025),\n",
    "                                val_shift_limit=(-25, 25),\n",
    "                                u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    return image\n",
    "\n",
    "def random_transform(image,\n",
    "                     seed=1,\n",
    "                     rotation_range=40,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        data_gen_args = dict(rotation_range=rotation_range,\n",
    "                             width_shift_range=width_shift_range,\n",
    "                             height_shift_range=height_shift_range,\n",
    "                             horizontal_flip=horizontal_flip)\n",
    "        image_data_gen = ImageDataGenerator(**data_gen_args)\n",
    "        image = image_data_gen.random_transform(image, seed)\n",
    "    return image\n",
    "\n",
    "def data_augmentation(image, seed=1):\n",
    "    image = random_hue_saturation_value(image)\n",
    "    image = random_transform(image, seed=1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#打乱训练样本，然后按照顺序读取batch训练样本。。。。\n",
    "def train_data_generator(images, batch_size, augment=True, seed=1):\n",
    "    random.shuffle(images) #打乱训练样本\n",
    "    while True:\n",
    "        for base in range(0, len(images), batch_size):\n",
    "            image_batch = []\n",
    "            y_batch = []\n",
    "            for offset in range(batch_size):\n",
    "                idx = base + offset\n",
    "                if idx >= len(images):\n",
    "                    break\n",
    "                image_name = images[idx].split(' ')[0]\n",
    "                #print(image_name)\n",
    "                image_array = load_img_array(image_name, grayscale=False)\n",
    "                #数据增强开关\n",
    "                if augment:\n",
    "                    image_array = data_augmentation(image_array, seed + idx)\n",
    "\n",
    "                image_batch.append(image_array)\n",
    "                y_batch.append(images[idx].split(' ')[1])\n",
    "            image_batch = np.array(image_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            y_batch = to_categorical(y_batch, 24) # 需要onehot编码，生成最后softmax的格式\n",
    "            yield image_batch, y_batch\n",
    "\n",
    "        \n",
    "def get_train_imgs(TRIAN_TXT):\n",
    "    all_images = []\n",
    "    with open(TRIAN_TXT,'r') as f:\n",
    "        for line in f:\n",
    "            all_images.append(line.strip('\\n'))\n",
    "    f.close()\n",
    "    random.shuffle(all_images)\n",
    "    return all_images\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create and train model and save model\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#准备训练数据，切分训练集与测试集\n",
    "all_train_images = get_train_imgs((TRIAN_TXT))\n",
    "train_images, validation_images = train_test_split(all_train_images, train_size=0.94, test_size=0.06, random_state=42)\n",
    "print(\"Number of train_images: {}\".format(len(train_images)))\n",
    "print(\"Number of validation_images: {}\".format(len(validation_images)))\n",
    "train_gen = train_data_generator(train_images, TRAIN_BATCH_SIZE, augment=True)\n",
    "validation_gen = train_data_generator(validation_images, TRAIN_BATCH_SIZE, augment=False)\n",
    "print(\"train and valid generator is ok\")\n",
    "\n",
    "steps_per_epoch = len(train_images) / TRAIN_BATCH_SIZE\n",
    "validation_steps = len(validation_images) / TRAIN_BATCH_SIZE\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps) \n",
    "\n",
    "\n",
    "#回调函数\n",
    "callbacks = [EarlyStopping(monitor='val_acc',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.00001,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_acc',\n",
    "                               factor=0.1,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.00001,\n",
    "                               cooldown=0,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_acc',\n",
    "                             filepath=BEST_WEIGHTS_FILE,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir=TF_LOG_DIR)]\n",
    " \n",
    "\n",
    "# create the base pre-trained model\n",
    "#model.load_weights('')\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "# add a logistic layer\n",
    "print(x.shape)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "# #-------------------------------------------------------------------------step1\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer=RMSprop(lr=LR1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# #save mode\n",
    "# def save_model(model, model_file):\n",
    "#     model_json_string = model.to_json()\n",
    "#     with open(model_file, 'w') as mf:\n",
    "#         mf.write(model_json_string)\n",
    "# save_model(model, MODEL_FILE)\n",
    "# # train the model on the new data for a few epochs\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS1,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from model. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "#-------------------------------------------------------------------------step2\n",
    "# we chose to train the some blocks, i.e. we will freeze the rest blocks\n",
    "# for layer in model.layers[:40]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[40:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "model.load_weights('/mogu/lingfei/project/cate4/resnet50/model_file/weight-0.09931645290726561.hdf5')\n",
    "model.compile(optimizer=RMSprop(lr=LR2), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "#------------------------------------------------------------------------- step3\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(optimizer=SGD(lr=LR3, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps,\n",
    "#                     workers=3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mogu/lingfei/install/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train_images: 852611\n",
      "Number of validation_images: 54422\n",
      "train and valid generator is ok\n",
      "steps_per_epoch: 26644.09375\n",
      "validation_steps: 1700.6875\n",
      "(?, 2048)\n",
      "Epoch 1/50\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.5074 - acc: 0.8449\n",
      "Epoch 00001: val_acc improved from -inf to 0.83336, saving model to /mogu/lingfei/project/cate4/resnet50/model_file/weight-0.8333578332335897.hdf5\n",
      "26645/26644 [==============================] - 24401s 916ms/step - loss: 0.5074 - acc: 0.8449 - val_loss: 0.5876 - val_acc: 0.8334\n",
      "Epoch 2/50\n",
      "26644/26644 [============================>.] - ETA: 0s - loss: 0.5060 - acc: 0.8455\n",
      "Epoch 00002: val_acc improved from 0.83336 to 0.85528, saving model to /mogu/lingfei/project/cate4/resnet50/model_file/weight-0.8552791150571896.hdf5\n",
      "26645/26644 [==============================] - 24293s 912ms/step - loss: 0.5060 - acc: 0.8455 - val_loss: 0.4716 - val_acc: 0.8553\n",
      "Epoch 3/50\n",
      "22432/26644 [========================>.....] - ETA: 1:02:38 - loss: 0.5017 - acc: 0.8470"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# config\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TRIAN_TXT= '/mogu/lingfei/project/cate4/train_data/cate4_look_merchandise_weibo_train.txt'\n",
    "NUM_CLASSES =24\n",
    "INPUT_HEIGHT,INPUT_WIDTH =224, 224\n",
    "MODEL_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/' + 'resnet50.json'\n",
    "BEST_WEIGHTS_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/'+'weight-{val_acc}.hdf5'\n",
    "TF_LOG_DIR = '/mogu/lingfei/project/cate4/resnet50/log'\n",
    "\n",
    "#the epoch of diff steps\n",
    "EPOCHS1 = 2\n",
    "EPOCHS2 = 4\n",
    "EPOCHS3 = 50\n",
    "\n",
    "#use diff learning rate in diff steps\n",
    "LR1 = 0.001\n",
    "LR2 = 0.0005\n",
    "LR3 = 0.0005\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# prepare data and data augmentation\n",
    "# ------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def load_img_array(image_name, grayscale=False, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n",
    "    img = image.load_img(image_name, grayscale)\n",
    "    resize_img = img.resize(target_size)\n",
    "    img_array = image.img_to_array(resize_img)/ 255.0\n",
    "    return img_array\n",
    "\n",
    "def random_hue_saturation_value(image,\n",
    "                                hue_shift_limit=(-15, 15),\n",
    "                                sat_shift_limit=(-0.025, 0.025),\n",
    "                                val_shift_limit=(-25, 25),\n",
    "                                u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    return image\n",
    "\n",
    "def random_transform(image,\n",
    "                     seed=1,\n",
    "                     rotation_range=40,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        data_gen_args = dict(rotation_range=rotation_range,\n",
    "                             width_shift_range=width_shift_range,\n",
    "                             height_shift_range=height_shift_range,\n",
    "                             horizontal_flip=horizontal_flip)\n",
    "        image_data_gen = ImageDataGenerator(**data_gen_args)\n",
    "        image = image_data_gen.random_transform(image, seed)\n",
    "    return image\n",
    "\n",
    "def data_augmentation(image, seed=1):\n",
    "    image = random_hue_saturation_value(image)\n",
    "    image = random_transform(image, seed=1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#打乱训练样本，然后按照顺序读取batch训练样本。。。。\n",
    "def train_data_generator(images, batch_size, augment=True, seed=1):\n",
    "    random.shuffle(images) #打乱训练样本\n",
    "    while True:\n",
    "        for base in range(0, len(images), batch_size):\n",
    "            image_batch = []\n",
    "            y_batch = []\n",
    "            for offset in range(batch_size):\n",
    "                idx = base + offset\n",
    "                if idx >= len(images):\n",
    "                    break\n",
    "                image_name = images[idx].split(' ')[0]\n",
    "                #print(image_name)\n",
    "                image_array = load_img_array(image_name, grayscale=False)\n",
    "                #数据增强开关\n",
    "                if augment:\n",
    "                    image_array = data_augmentation(image_array, seed + idx)\n",
    "\n",
    "                image_batch.append(image_array)\n",
    "                y_batch.append(images[idx].split(' ')[1])\n",
    "            image_batch = np.array(image_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            y_batch = to_categorical(y_batch, 24) # 需要onehot编码，生成最后softmax的格式\n",
    "            yield image_batch, y_batch\n",
    "\n",
    "        \n",
    "def get_train_imgs(TRIAN_TXT):\n",
    "    all_images = []\n",
    "    with open(TRIAN_TXT,'r') as f:\n",
    "        for line in f:\n",
    "            all_images.append(line.strip('\\n'))\n",
    "    f.close()\n",
    "    random.shuffle(all_images)\n",
    "    return all_images\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create and train model and save mode\n",
    "# ------------------------------------------------------------------\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#准备训练数据，切分训练集与测试集\n",
    "all_train_images = get_train_imgs((TRIAN_TXT))\n",
    "train_images, validation_images = train_test_split(all_train_images, train_size=0.94, test_size=0.06, random_state=42)\n",
    "print(\"Number of train_images: {}\".format(len(train_images)))\n",
    "print(\"Number of validation_images: {}\".format(len(validation_images)))\n",
    "train_gen = train_data_generator(train_images, TRAIN_BATCH_SIZE, augment=True)\n",
    "validation_gen = train_data_generator(validation_images, TRAIN_BATCH_SIZE, augment=False)\n",
    "print(\"train and valid generator is ok\")\n",
    "\n",
    "steps_per_epoch = len(train_images) / TRAIN_BATCH_SIZE\n",
    "validation_steps = len(validation_images) / TRAIN_BATCH_SIZE\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps) \n",
    "\n",
    "\n",
    "#回调函数\n",
    "callbacks = [EarlyStopping(monitor='val_acc',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.00001,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_acc',\n",
    "                               factor=0.1,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.00001,\n",
    "                               cooldown=0,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_acc',\n",
    "                             filepath=BEST_WEIGHTS_FILE,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir=TF_LOG_DIR)]\n",
    " \n",
    "\n",
    "# create the base pre-trained model\n",
    "#model.load_weights('')\n",
    "base_model = ResNet50(include_top=False, input_shape=(INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "# add a logistic layer\n",
    "print(x.shape)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "# #-------------------------------------------------------------------------step1\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "    \n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer=RMSprop(lr=LR1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# #save mode\n",
    "# def save_model(model, model_file):\n",
    "#     model_json_string = model.to_json()\n",
    "#     with open(model_file, 'w') as mf:\n",
    "#         mf.write(model_json_string)\n",
    "# save_model(model, MODEL_FILE)\n",
    "# # train the model on the new data for a few epochs\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS1,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from model. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "#-------------------------------------------------------------------------step2\n",
    "# we chose to train the some blocks, i.e. we will freeze the rest blocks\n",
    "# for layer in model.layers[:40]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[40:]:\n",
    "#     layer.trainable = True\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "model.load_weights('/mogu/lingfei/project/cate4/resnet50/model_file/weight-0.8287089779912244.hdf5')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=RMSprop(lr=LR3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "#------------------------------------------------------------------------- step3\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(optimizer=SGD(lr=LR3, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps,\n",
    "#                     workers=3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train_images: 653980\n",
      "Number of validation_images: 53026\n",
      "train and valid generator is ok\n",
      "steps_per_epoch: 10218.4375\n",
      "validation_steps: 828.53125\n",
      "(?, 2048)\n",
      "Epoch 1/20\n",
      "  139/10218 [..............................] - ETA: 17:25:09 - loss: 4.6027 - acc: 0.4319"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# config\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "TRIAN_TXT= '/mogu/lingfei/project/cate4/clean_trian_data/clean_train_resnet50-0.75.txt'\n",
    "NUM_CLASSES =24\n",
    "INPUT_HEIGHT,INPUT_WIDTH =224, 224\n",
    "MODEL_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/fine/' + 'resnet50.json'\n",
    "BEST_WEIGHTS_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/fine/'+'weight-{val_acc}.hdf5'\n",
    "TF_LOG_DIR = '/mogu/lingfei/project/cate4/resnet50/log'\n",
    "\n",
    "#the epoch of diff steps\n",
    "EPOCHS1 = 2\n",
    "EPOCHS2 = 4\n",
    "EPOCHS3 = 20\n",
    "\n",
    "#use diff learning rate in diff steps\n",
    "LR1 = 0.001\n",
    "LR2 = 0.0005\n",
    "LR3 = 0.00001\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# prepare data and data augmentation\n",
    "# ------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def load_img_array(image_name, grayscale=False, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n",
    "    img = image.load_img(image_name, grayscale)\n",
    "    resize_img = img.resize(target_size)\n",
    "    img_array = image.img_to_array(resize_img)/ 255.0\n",
    "    return img_array\n",
    "\n",
    "def random_hue_saturation_value(image,\n",
    "                                hue_shift_limit=(-15, 15),\n",
    "                                sat_shift_limit=(-0.025, 0.025),\n",
    "                                val_shift_limit=(-25, 25),\n",
    "                                u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    return image\n",
    "\n",
    "def random_transform(image,\n",
    "                     seed=1,\n",
    "                     rotation_range=50,\n",
    "                     width_shift_range=0.2,\n",
    "                     height_shift_range=0.2,\n",
    "                     horizontal_flip=True,\n",
    "                     u=0.4):\n",
    "    if np.random.random() < u:\n",
    "        data_gen_args = dict(rotation_range=rotation_range,\n",
    "                             width_shift_range=width_shift_range,\n",
    "                             height_shift_range=height_shift_range,\n",
    "                             horizontal_flip=horizontal_flip)\n",
    "        image_data_gen = ImageDataGenerator(**data_gen_args)\n",
    "        image = image_data_gen.random_transform(image, seed)\n",
    "    return image\n",
    "\n",
    "def data_augmentation(image, seed=1):\n",
    "    image = random_hue_saturation_value(image)\n",
    "    image = random_transform(image, seed=1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#打乱训练样本，然后按照顺序读取batch训练样本。。。。\n",
    "def train_data_generator(images, batch_size, augment=True, seed=1):\n",
    "    random.shuffle(images) #打乱训练样本\n",
    "    while True:\n",
    "        for base in range(0, len(images), batch_size):\n",
    "            image_batch = []\n",
    "            y_batch = []\n",
    "            for offset in range(batch_size):\n",
    "                idx = base + offset\n",
    "                if idx >= len(images):\n",
    "                    break\n",
    "                image_name = images[idx].split(' ')[0]\n",
    "                #print(image_name)\n",
    "                image_array = load_img_array(image_name, grayscale=False)\n",
    "                #数据增强开关\n",
    "                if augment:\n",
    "                    image_array = data_augmentation(image_array, seed + idx)\n",
    "\n",
    "                image_batch.append(image_array)\n",
    "                y_batch.append(images[idx].split(' ')[1])\n",
    "            image_batch = np.array(image_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            y_batch = to_categorical(y_batch, 24) # 需要onehot编码，生成最后softmax的格式\n",
    "            yield image_batch, y_batch\n",
    "\n",
    "        \n",
    "def get_train_imgs(TRIAN_TXT):\n",
    "    all_images = []\n",
    "    with open(TRIAN_TXT,'r') as f:\n",
    "        for line in f:\n",
    "            all_images.append(line.strip('\\n'))\n",
    "    f.close()\n",
    "    random.shuffle(all_images)\n",
    "    return all_images\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create and train model and save mode\n",
    "# ------------------------------------------------------------------\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#准备训练数据，切分训练集与测试集\n",
    "all_train_images = get_train_imgs((TRIAN_TXT))\n",
    "train_images, validation_images = train_test_split(all_train_images, train_size=0.925, test_size=0.075, random_state=42)\n",
    "print(\"Number of train_images: {}\".format(len(train_images)))\n",
    "print(\"Number of validation_images: {}\".format(len(validation_images)))\n",
    "train_gen = train_data_generator(train_images, TRAIN_BATCH_SIZE, augment=True)\n",
    "validation_gen = train_data_generator(validation_images, TRAIN_BATCH_SIZE, augment=False)\n",
    "print(\"train and valid generator is ok\")\n",
    "\n",
    "steps_per_epoch = len(train_images) / TRAIN_BATCH_SIZE\n",
    "validation_steps = len(validation_images) / TRAIN_BATCH_SIZE\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps) \n",
    "\n",
    "\n",
    "#回调函数\n",
    "callbacks = [EarlyStopping(monitor='val_acc',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.00001,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_acc',\n",
    "                               factor=0.1,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.00001,\n",
    "                               cooldown=0,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_acc',\n",
    "                             filepath=BEST_WEIGHTS_FILE,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir=TF_LOG_DIR)]\n",
    " \n",
    "\n",
    "# create the base pre-trained model\n",
    "#model.load_weights('')\n",
    "base_model = ResNet50(include_top=False, input_shape=(INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "# add a logistic layer\n",
    "print(x.shape)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "# #-------------------------------------------------------------------------step1\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "    \n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer=RMSprop(lr=LR1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# #save mode\n",
    "# def save_model(model, model_file):\n",
    "#     model_json_string = model.to_json()\n",
    "#     with open(model_file, 'w') as mf:\n",
    "#         mf.write(model_json_string)\n",
    "# save_model(model, MODEL_FILE)\n",
    "# # train the model on the new data for a few epochs\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS1,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from model. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "#-------------------------------------------------------------------------step2\n",
    "# we chose to train the some blocks, i.e. we will freeze the rest blocks\n",
    "# for layer in model.layers[:40]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[40:]:\n",
    "#     layer.trainable = True\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "model.load_weights('/mogu/lingfei/project/cate4/resnet50/model_file/weight-0.857208481868333.hdf5')\n",
    "# for layer in model.layers[:10]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[10:]:\n",
    "#     layer.trainable = True\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=LR3, momentum=0.9, decay = 0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps)\n",
    "#------------------------------------------------------------------------- step3\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(optimizer=SGD(lr=LR3, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "#                     callbacks=callbacks,\n",
    "#                     validation_data=validation_gen, validation_steps=validation_steps,\n",
    "#                     workers=3, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
