{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# config\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TRIAN_TXT= '/mogu/lingfei/project/cate4/train_data/cate4_look_merchandise_weibo_train.txt'\n",
    "NUM_CLASSES =24\n",
    "INPUT_HEIGHT,INPUT_WIDTH =224, 224\n",
    "MODEL_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/' + 'resnet50.json'\n",
    "BEST_WEIGHTS_FILE = '/mogu/lingfei/project/cate4/resnet50/model_file/'+'weight-{val_acc}.hdf5'\n",
    "TF_LOG_DIR = '/mogu/lingfei/project/cate4/resnet50/log'\n",
    "\n",
    "#the epoch of diff steps\n",
    "EPOCHS1 = 2\n",
    "EPOCHS2 = 4\n",
    "EPOCHS3 = 5\n",
    "\n",
    "#use diff learning rate in diff steps\n",
    "LR1 = 0.001\n",
    "LR2 = 0.0005\n",
    "LR3 = 0.0001\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# prepare data and data augmentation\n",
    "# ------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def load_img_array(image_name, grayscale=False, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n",
    "    img = image.load_img(image_name, grayscale)\n",
    "    resize_img = img.resize(target_size)\n",
    "    img_array = image.img_to_array(resize_img)/ 255.0\n",
    "    return img_array\n",
    "\n",
    "def random_hue_saturation_value(image,\n",
    "                                hue_shift_limit=(-15, 15),\n",
    "                                sat_shift_limit=(-0.025, 0.025),\n",
    "                                val_shift_limit=(-25, 25),\n",
    "                                u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    return image\n",
    "\n",
    "def random_transform(image,\n",
    "                     seed=1,\n",
    "                     rotation_range=40,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     u=0.25):\n",
    "    if np.random.random() < u:\n",
    "        data_gen_args = dict(rotation_range=rotation_range,\n",
    "                             width_shift_range=width_shift_range,\n",
    "                             height_shift_range=height_shift_range,\n",
    "                             horizontal_flip=horizontal_flip)\n",
    "        image_data_gen = ImageDataGenerator(**data_gen_args)\n",
    "        image = image_data_gen.random_transform(image, seed)\n",
    "    return image\n",
    "\n",
    "def data_augmentation(image, seed=1):\n",
    "    image = random_hue_saturation_value(image)\n",
    "    image = random_transform(image, seed=1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#打乱训练样本，然后按照顺序读取batch训练样本。。。。\n",
    "def train_data_generator(images, batch_size, augment=True, seed=1):\n",
    "    random.shuffle(images) #打乱训练样本\n",
    "    while True:\n",
    "        for base in range(0, len(images), batch_size):\n",
    "            image_batch = []\n",
    "            y_batch = []\n",
    "            for offset in range(batch_size):\n",
    "                idx = base + offset\n",
    "                if idx >= len(images):\n",
    "                    break\n",
    "                image_name = images[idx].split(' ')[0]\n",
    "                #print(image_name)\n",
    "                image_array = load_img_array(image_name, grayscale=False)\n",
    "                #数据增强开关\n",
    "                if augment:\n",
    "                    image_array = data_augmentation(image_array, seed + idx)\n",
    "\n",
    "                image_batch.append(image_array)\n",
    "                y_batch.append(images[idx].split(' ')[1])\n",
    "            image_batch = np.array(image_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            y_batch = to_categorical(y_batch, 24) # 需要onehot编码，生成最后softmax的格式\n",
    "            yield image_batch, y_batch\n",
    "\n",
    "        \n",
    "def get_train_imgs(TRIAN_TXT):\n",
    "    all_images = []\n",
    "    with open(TRIAN_TXT,'r') as f:\n",
    "        for line in f:\n",
    "            all_images.append(line.strip('\\n'))\n",
    "    f.close()\n",
    "    random.shuffle(all_images)\n",
    "    return all_images\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create and train model and save mode\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#准备训练数据，切分训练集与测试集\n",
    "all_train_images = get_train_imgs((TRIAN_TXT))\n",
    "train_images, validation_images = train_test_split(all_train_images, train_size=0.94, test_size=0.06, random_state=42)\n",
    "print(\"Number of train_images: {}\".format(len(train_images)))\n",
    "print(\"Number of validation_images: {}\".format(len(validation_images)))\n",
    "train_gen = train_data_generator(train_images, TRAIN_BATCH_SIZE, augment=True)\n",
    "validation_gen = train_data_generator(validation_images, TRAIN_BATCH_SIZE, augment=False)\n",
    "print(\"train and valid generator is ok\")\n",
    "\n",
    "steps_per_epoch = len(train_images) / TRAIN_BATCH_SIZE\n",
    "validation_steps = len(validation_images) / TRAIN_BATCH_SIZE\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps) \n",
    "\n",
    "\n",
    "#回调函数\n",
    "callbacks = [EarlyStopping(monitor='val_acc',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.00001,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_acc',\n",
    "                               factor=0.1,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.00001,\n",
    "                               cooldown=0,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_acc',\n",
    "                             filepath=BEST_WEIGHTS_FILE,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir=TF_LOG_DIR)]\n",
    " \n",
    "\n",
    "# create the base pre-trained model\n",
    "#model.load_weights('')\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "# add a logistic layer\n",
    "print(x.shape)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "# #-------------------------------------------------------------------------step1\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer=RMSprop(lr=LR1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# #save mode\n",
    "def save_model(model, model_file):\n",
    "    model_json_string = model.to_json()\n",
    "    with open(model_file, 'w') as mf:\n",
    "        mf.write(model_json_string)\n",
    "save_model(model, MODEL_FILE)\n",
    "\n",
    "# # train the model on the new data for a few epochs\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "#-------------------------------------------------------------------------step2\n",
    "# we chose to train the some blocks, i.e. we will freeze the rest blocks\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "    \n",
    "for layer in model.layers[:40]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[40:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "# model.load_weights('/mogu/lingfei/project/cate4/resnet50/model_file/weight-0.09931645290726561.hdf5')\n",
    "model.compile(optimizer=RMSprop(lr=LR2), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps)\n",
    "\n",
    "#------------------------------------------------------------------------- step3\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=LR3, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validation_gen, validation_steps=validation_steps,\n",
    "                    workers=3, use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
